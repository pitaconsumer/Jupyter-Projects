{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying Fake-Authentic Classifier Over Facebook Political Ads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Context:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem:\n",
    "\n",
    "## Question: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methodology:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Learning a Classifier Model from Articles Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-07-17 16:16:51--  https://github.com/pitaconsumer/some-datasets/blob/master/572515_1037534_compressed_Fake.csv.zip?raw=true\n",
      "Resolving github.com (github.com)... 192.30.255.112\n",
      "Connecting to github.com (github.com)|192.30.255.112|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://github.com/pitaconsumer/some-datasets/raw/master/572515_1037534_compressed_Fake.csv.zip [following]\n",
      "--2020-07-17 16:16:52--  https://github.com/pitaconsumer/some-datasets/raw/master/572515_1037534_compressed_Fake.csv.zip\n",
      "Reusing existing connection to github.com:443.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://raw.githubusercontent.com/pitaconsumer/some-datasets/master/572515_1037534_compressed_Fake.csv.zip [following]\n",
      "--2020-07-17 16:16:52--  https://raw.githubusercontent.com/pitaconsumer/some-datasets/master/572515_1037534_compressed_Fake.csv.zip\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.192.133, 151.101.0.133, 151.101.128.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.192.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 416 Range Not Satisfiable\n",
      "\n",
      "    The file is already fully retrieved; nothing to do.\n",
      "\n",
      "--2020-07-17 16:16:53--  https://github.com/pitaconsumer/some-datasets/blob/master/572515_1037534_compressed_True.csv.zip?raw=true\n",
      "Resolving github.com (github.com)... 192.30.255.112\n",
      "Connecting to github.com (github.com)|192.30.255.112|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://github.com/pitaconsumer/some-datasets/raw/master/572515_1037534_compressed_True.csv.zip [following]\n",
      "--2020-07-17 16:16:53--  https://github.com/pitaconsumer/some-datasets/raw/master/572515_1037534_compressed_True.csv.zip\n",
      "Reusing existing connection to github.com:443.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://raw.githubusercontent.com/pitaconsumer/some-datasets/master/572515_1037534_compressed_True.csv.zip [following]\n",
      "--2020-07-17 16:16:54--  https://raw.githubusercontent.com/pitaconsumer/some-datasets/master/572515_1037534_compressed_True.csv.zip\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.64.133, 151.101.192.133, 151.101.128.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.64.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 416 Range Not Satisfiable\n",
      "\n",
      "    The file is already fully retrieved; nothing to do.\n",
      "\n",
      "Archive:  572515_1037534_compressed_Fake.csv.zip?raw=true\n",
      "  inflating: Fake.csv                \n",
      "Archive:  572515_1037534_compressed_True.csv.zip?raw=true\n",
      "  inflating: True.csv                \n"
     ]
    }
   ],
   "source": [
    "!wget -c 'https://github.com/pitaconsumer/some-datasets/blob/master/572515_1037534_compressed_Fake.csv.zip?raw=true'\n",
    "!wget -c \"https://github.com/pitaconsumer/some-datasets/blob/master/572515_1037534_compressed_True.csv.zip?raw=true\"\n",
    "!unzip -o  \"572515_1037534_compressed_Fake.csv.zip?raw=true\"\n",
    "!unzip -o \"572515_1037534_compressed_True.csv.zip?raw=true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in /usr/local/lib/python3.6/dist-packages (2.3.2)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (4.46.1)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.7.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.2)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy) (47.1.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.23.0)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.18.5)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.2)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (3.0.2)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.0.3)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.0)\n",
      "Requirement already satisfied: thinc==7.4.1 in /usr/local/lib/python3.6/dist-packages (from spacy) (7.4.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.4.5.2)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.9)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.25.9)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy) (1.6.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (3.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: en_core_web_lg==2.3.1 from https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-2.3.1/en_core_web_lg-2.3.1.tar.gz#egg=en_core_web_lg==2.3.1 in /usr/local/lib/python3.6/dist-packages (2.3.1)\n",
      "Requirement already satisfied: spacy<2.4.0,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from en_core_web_lg==2.3.1) (2.3.2)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (3.0.2)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (47.1.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (1.0.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (2.23.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (1.18.5)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (1.1.3)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (2.0.3)\n",
      "Requirement already satisfied: thinc==7.4.1 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (7.4.1)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (0.4.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (4.46.1)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (1.0.0)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (1.0.2)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (0.7.1)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (2.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (2020.4.5.2)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (1.25.9)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (1.6.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (3.1.0)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('en_core_web_lg')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting textblob\n",
      "  Downloading textblob-0.15.3-py2.py3-none-any.whl (636 kB)\n",
      "\u001b[K     |████████████████████████████████| 636 kB 13.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: nltk>=3.1 in /usr/local/lib/python3.6/dist-packages (from textblob) (3.5)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from nltk>=3.1->textblob) (7.1.2)\n",
      "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from nltk>=3.1->textblob) (2020.6.8)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from nltk>=3.1->textblob) (0.15.1)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from nltk>=3.1->textblob) (4.46.1)\n",
      "Installing collected packages: textblob\n",
      "Successfully installed textblob-0.15.3\n"
     ]
    }
   ],
   "source": [
    "!pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting preprocessor\n",
      "  Downloading preprocessor-1.1.3.tar.gz (4.2 kB)\n",
      "Building wheels for collected packages: preprocessor\n",
      "  Building wheel for preprocessor (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for preprocessor: filename=preprocessor-1.1.3-py3-none-any.whl size=4477 sha256=d2a8628697ae75b1cebe72d62cb55c5c5ff9e4d3958ef5edc1887e2f4cdbb65c\n",
      "  Stored in directory: /root/.cache/pip/wheels/22/ae/f5/38dbc573cab3fc25d865fc55f8845d40742161416220532ea2\n",
      "Successfully built preprocessor\n",
      "Installing collected packages: preprocessor\n",
      "Successfully installed preprocessor-1.1.3\n"
     ]
    }
   ],
   "source": [
    "!pip install preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting seaborn\n",
      "  Downloading seaborn-0.10.1-py3-none-any.whl (215 kB)\n",
      "\u001b[K     |████████████████████████████████| 215 kB 342 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pandas>=0.22.0 in /usr/local/lib/python3.6/dist-packages (from seaborn) (1.0.4)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from seaborn) (1.18.5)\n",
      "Requirement already satisfied: matplotlib>=2.1.2 in /usr/local/lib/python3.6/dist-packages (from seaborn) (3.2.1)\n",
      "Requirement already satisfied: scipy>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from seaborn) (1.4.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.22.0->seaborn) (2020.1)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.22.0->seaborn) (2.8.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.2->seaborn) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.2->seaborn) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.2->seaborn) (1.2.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas>=0.22.0->seaborn) (1.15.0)\n",
      "Installing collected packages: seaborn\n",
      "Successfully installed seaborn-0.10.1\n"
     ]
    }
   ],
   "source": [
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy \n",
    "import en_core_web_lg\n",
    "\n",
    "spacy.prefer_gpu()\n",
    "nlp = en_core_web_lg.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas(desc=\"progress bar\")\n",
    "\n",
    "\n",
    "import preprocessor\n",
    "from textblob import TextBlob\n",
    "import statistics\n",
    "from typing import List\n",
    "\n",
    "\n",
    "import scipy\n",
    "\n",
    "import spacy\n",
    "import nltk\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_df = pd.read_csv('Fake.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 26 µs, sys: 1e+03 ns, total: 27 µs\n",
      "Wall time: 31.2 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(23481, 4)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time fake_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_df = pd.read_csv(\"True.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "progress bar:  63%|██████▎   | 14873/23481 [13:47<08:04, 17.78it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "progress bar: 100%|██████████| 23481/23481 [22:56<00:00, 17.06it/s]\n"
     ]
    }
   ],
   "source": [
    "fake_vectors = fake_df['text'].progress_apply(lambda x: pd.Series(nlp(x).doc.vector.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "progress bar: 100%|██████████| 21417/21417 [17:33<00:00, 20.34it/s]\n"
     ]
    }
   ],
   "source": [
    "true_vectors = true_df['text'].progress_apply(lambda x: pd.Series(nlp(x).doc.vector.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_vectors['y'] = 0\n",
    "true_vectors['y'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_vectors.to_pickle('fake_vectors.pickle')\n",
    "true_vectors.to_pickle('true_vectors.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Facebook Political Ads Classified Into Fake Versus Authentic Via Random Forest Model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CLF from Training of fake data sets\n",
    "#### Predict outcomes for Facebook \n",
    "    Y_fb_pred = clf.fit(X_train_fake, Y_train_true).predict(X_test_fb_pol)\n",
    "clf.fit(X_fb_pol, Y_fb_pred).  #Test Set is FB Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.5)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from nltk) (4.46.1)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from nltk) (0.15.1)\n",
      "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from nltk) (2020.6.8)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from nltk) (7.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from wordcloud import WordCloud,STOPWORDS\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "import re,string,unicodedata\n",
    "from nltk.stem import WordNetLemmatizer,PorterStemmer\n",
    "import os\n",
    "import gc\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import  Counter\n",
    "\n",
    "#stop = set(stopwords.words('english'))\n",
    "#punctuation = list(string.punctuation)\n",
    "#stop.update(punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>html</th>\n",
       "      <th>political</th>\n",
       "      <th>not_political</th>\n",
       "      <th>title</th>\n",
       "      <th>message</th>\n",
       "      <th>thumbnail</th>\n",
       "      <th>created_at</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>lang</th>\n",
       "      <th>...</th>\n",
       "      <th>suppressed</th>\n",
       "      <th>targets</th>\n",
       "      <th>advertiser</th>\n",
       "      <th>entities</th>\n",
       "      <th>page</th>\n",
       "      <th>lower_page</th>\n",
       "      <th>targetings</th>\n",
       "      <th>paid_for_by</th>\n",
       "      <th>targetedness</th>\n",
       "      <th>listbuilding_fundraising_proba</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hyperfeed_story_id_5c9baa3ee0ec08073500042</td>\n",
       "      <td>&lt;div class=\"_5pa- userContentWrapper\"&gt;&lt;div cla...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>League of Conservation Voters</td>\n",
       "      <td>&lt;p&gt;BREAKING: Trump’s Department of the Interio...</td>\n",
       "      <td>https://pp-facebook-ads.s3.amazonaws.com/v/t1....</td>\n",
       "      <td>2019-03-27 16:52:25.625455+00</td>\n",
       "      <td>2019-03-27 16:52:25.625455+00</td>\n",
       "      <td>en-US</td>\n",
       "      <td>...</td>\n",
       "      <td>f</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{\"entity\": \"Endangered Species Act\", \"entity_...</td>\n",
       "      <td>https://www.facebook.com/LCVoters/</td>\n",
       "      <td>https://www.facebook.com/lcvoters/</td>\n",
       "      <td>NaN</td>\n",
       "      <td>League of Conservation Voters</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.647945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hyperfeed_story_id_5c9bb2a2413852086735771</td>\n",
       "      <td>&lt;div class=\"_5pa- userContentWrapper\"&gt;&lt;div cla...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Indivisible Guide</td>\n",
       "      <td>&lt;p&gt;The Mueller investigation is over. Special ...</td>\n",
       "      <td>https://pp-facebook-ads.s3.amazonaws.com/v/t1....</td>\n",
       "      <td>2019-03-27 17:28:14.096849+00</td>\n",
       "      <td>2019-03-27 17:28:14.096849+00</td>\n",
       "      <td>en-US</td>\n",
       "      <td>...</td>\n",
       "      <td>f</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{\"entity\": \"Americans\", \"entity_type\": \"Group...</td>\n",
       "      <td>https://www.facebook.com/indivisibleguide/</td>\n",
       "      <td>https://www.facebook.com/indivisibleguide/</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Indivisible Project</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.350635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hyperfeed_story_id_5c9bb4fa461731e29426627</td>\n",
       "      <td>&lt;div class=\"_5pa- userContentWrapper\"&gt;&lt;div cla...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>International Rescue Committee</td>\n",
       "      <td>&lt;p&gt;Zimbabwe is reeling from the impact of Cycl...</td>\n",
       "      <td>https://pp-facebook-ads.s3.amazonaws.com/v/t1....</td>\n",
       "      <td>2019-03-27 17:38:23.101377+00</td>\n",
       "      <td>2019-03-27 17:38:23.101377+00</td>\n",
       "      <td>en-US</td>\n",
       "      <td>...</td>\n",
       "      <td>f</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{\"entity\": \"Zimbabwe\", \"entity_type\": \"Region\"}]</td>\n",
       "      <td>https://www.facebook.com/InternationalRescueCo...</td>\n",
       "      <td>https://www.facebook.com/internationalrescueco...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>International Rescue Committee</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23843380741530360</td>\n",
       "      <td>&lt;div class=\"_5pcr userContentWrapper\"&gt;&lt;div cla...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Covenant House International</td>\n",
       "      <td>&lt;p&gt;What more can you do in the final hours of ...</td>\n",
       "      <td>https://pp-facebook-ads.s3.amazonaws.com/v/t1....</td>\n",
       "      <td>2018-12-30 20:59:13.879124+00</td>\n",
       "      <td>2018-12-30 20:59:13.879124+00</td>\n",
       "      <td>en-US</td>\n",
       "      <td>...</td>\n",
       "      <td>f</td>\n",
       "      <td>[{\"target\": \"Activity on the Facebook Family\"}...</td>\n",
       "      <td>Covenant House International</td>\n",
       "      <td>[]</td>\n",
       "      <td>https://www.facebook.com/CovenantHouse/</td>\n",
       "      <td>https://www.facebook.com/covenanthouse/</td>\n",
       "      <td>{\"&lt;div&gt;&lt;div class=\\\"_4-i0 _26c5\\\"&gt;&lt;div class=\\...</td>\n",
       "      <td>Covenant House International</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hyperfeed_story_id_5c9bb059454851c17741213</td>\n",
       "      <td>&lt;div class=\"_5pa- userContentWrapper\"&gt;&lt;div cla...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Planned Parenthood</td>\n",
       "      <td>&lt;p&gt;Say it loud, say it proud: Our rights, our ...</td>\n",
       "      <td>https://pp-facebook-ads.s3.amazonaws.com/v/t1....</td>\n",
       "      <td>2019-03-27 17:18:29.764002+00</td>\n",
       "      <td>2019-04-11 15:02:58.081112+00</td>\n",
       "      <td>en-US</td>\n",
       "      <td>...</td>\n",
       "      <td>f</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{\"entity\": \"Planned Parenthood\", \"entity_type...</td>\n",
       "      <td>https://www.facebook.com/PlannedParenthood/</td>\n",
       "      <td>https://www.facebook.com/plannedparenthood/</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Planned Parenthood Federation of America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162319</th>\n",
       "      <td>23843108782710078</td>\n",
       "      <td>&lt;div class=\"_5pcr userContentWrapper\"&gt;&lt;div cla...</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>Keep Them Accountable</td>\n",
       "      <td>&lt;p&gt;Rep. Katko voted for tax breaks for his wea...</td>\n",
       "      <td>https://pp-facebook-ads.s3.amazonaws.com/v/t1....</td>\n",
       "      <td>2018-10-19 10:31:52.466563+00</td>\n",
       "      <td>2018-10-22 11:40:06.24382+00</td>\n",
       "      <td>en-US</td>\n",
       "      <td>...</td>\n",
       "      <td>f</td>\n",
       "      <td>[{\"target\": \"Age\", \"segment\": \"18 and older\"},...</td>\n",
       "      <td>Keep Them Accountable</td>\n",
       "      <td>[{\"entity\": \"Katko\", \"entity_type\": \"Person\"}]</td>\n",
       "      <td>https://www.facebook.com/KeepThemAccountable18/</td>\n",
       "      <td>https://www.facebook.com/keepthemaccountable18/</td>\n",
       "      <td>{\"&lt;div&gt;&lt;div class=\\\"_4-i0 _26c5\\\"&gt;&lt;div class=\\...</td>\n",
       "      <td>HOUSE MAJORITY PAC, (202) 849-6052, AND PRIORI...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.116965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162320</th>\n",
       "      <td>23843034525850259</td>\n",
       "      <td>&lt;div class=\"_5pcr userContentWrapper\"&gt;&lt;div cla...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>National Republican Congressional Committee</td>\n",
       "      <td>&lt;p&gt;Illinois early voting is open NOW &amp;amp; you...</td>\n",
       "      <td>https://pp-facebook-ads.s3.amazonaws.com/v/t1....</td>\n",
       "      <td>2018-10-24 20:41:42.111865+00</td>\n",
       "      <td>2018-10-24 20:41:42.111865+00</td>\n",
       "      <td>en-US</td>\n",
       "      <td>...</td>\n",
       "      <td>f</td>\n",
       "      <td>[{\"target\": \"List\"}, {\"target\": \"Age\", \"segmen...</td>\n",
       "      <td>National Republican Congressional Committee</td>\n",
       "      <td>[{\"entity\": \"Illinois\", \"entity_type\": \"Region...</td>\n",
       "      <td>https://www.facebook.com/NRCC/</td>\n",
       "      <td>https://www.facebook.com/nrcc/</td>\n",
       "      <td>{\"&lt;div&gt;&lt;div class=\\\"_4-i0 _26c5\\\"&gt;&lt;div class=\\...</td>\n",
       "      <td>the NRCC and not authorized by any candidate o...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.312412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162321</th>\n",
       "      <td>23842997138670612</td>\n",
       "      <td>&lt;div class=\"_5pcr userContentWrapper\"&gt;&lt;div cla...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>POW Action Fund</td>\n",
       "      <td>&lt;p&gt;From your favorite peaks to the polling pla...</td>\n",
       "      <td>https://pp-facebook-ads.s3.amazonaws.com/v/t1....</td>\n",
       "      <td>2018-10-09 20:03:32.81012+00</td>\n",
       "      <td>2018-10-09 20:03:32.81012+00</td>\n",
       "      <td>en-US</td>\n",
       "      <td>...</td>\n",
       "      <td>f</td>\n",
       "      <td>[{\"target\": \"Segment\", \"segment\": \"US politics...</td>\n",
       "      <td>POW Action Fund</td>\n",
       "      <td>[]</td>\n",
       "      <td>https://www.facebook.com/POWActionFund/</td>\n",
       "      <td>https://www.facebook.com/powactionfund/</td>\n",
       "      <td>{\"&lt;div&gt;&lt;div class=\\\"_4-i0 _26c5\\\"&gt;&lt;div class=\\...</td>\n",
       "      <td>Protect Our Winters Action Fund</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.205220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162322</th>\n",
       "      <td>hyperfeed_story_id_5c8b16b11b8f86515960964</td>\n",
       "      <td>&lt;div class=\"_5pa- userContentWrapper\"&gt;&lt;div cla...</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>Beto O'Rourke</td>\n",
       "      <td>&lt;p&gt;Beto just announced he’s running for presid...</td>\n",
       "      <td>https://pp-facebook-ads.s3.amazonaws.com/v/t1....</td>\n",
       "      <td>2019-03-15 03:07:40.590249+00</td>\n",
       "      <td>2019-03-22 17:01:05.36319+00</td>\n",
       "      <td>en-US</td>\n",
       "      <td>...</td>\n",
       "      <td>f</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{\"entity\": \"Beto\", \"entity_type\": \"Region\"}]</td>\n",
       "      <td>https://www.facebook.com/betoorourke/</td>\n",
       "      <td>https://www.facebook.com/betoorourke/</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Beto for America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162323</th>\n",
       "      <td>23842885237930242</td>\n",
       "      <td>&lt;div class=\"_5pcr userContentWrapper\"&gt;&lt;div cla...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ACLU</td>\n",
       "      <td>&lt;p&gt;Claim your FREE ACLU Voter sticker today to...</td>\n",
       "      <td>https://pp-facebook-ads.s3.amazonaws.com/v/t1....</td>\n",
       "      <td>2018-08-08 02:54:51.076959+00</td>\n",
       "      <td>2018-08-08 20:03:36.302904+00</td>\n",
       "      <td>en-US</td>\n",
       "      <td>...</td>\n",
       "      <td>f</td>\n",
       "      <td>[{\"target\": \"Age\", \"segment\": \"35 to 54\"}, {\"t...</td>\n",
       "      <td>ACLU</td>\n",
       "      <td>[]</td>\n",
       "      <td>https://www.facebook.com/aclu/</td>\n",
       "      <td>https://www.facebook.com/aclu/</td>\n",
       "      <td>{\"&lt;div&gt;&lt;div class=\\\"_4-i0 _26c5\\\"&gt;&lt;div class=\\...</td>\n",
       "      <td>the ACLU</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.354132</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>162324 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                id  \\\n",
       "0       hyperfeed_story_id_5c9baa3ee0ec08073500042   \n",
       "1       hyperfeed_story_id_5c9bb2a2413852086735771   \n",
       "2       hyperfeed_story_id_5c9bb4fa461731e29426627   \n",
       "3                                23843380741530360   \n",
       "4       hyperfeed_story_id_5c9bb059454851c17741213   \n",
       "...                                            ...   \n",
       "162319                           23843108782710078   \n",
       "162320                           23843034525850259   \n",
       "162321                           23842997138670612   \n",
       "162322  hyperfeed_story_id_5c8b16b11b8f86515960964   \n",
       "162323                           23842885237930242   \n",
       "\n",
       "                                                     html  political  \\\n",
       "0       <div class=\"_5pa- userContentWrapper\"><div cla...          0   \n",
       "1       <div class=\"_5pa- userContentWrapper\"><div cla...          0   \n",
       "2       <div class=\"_5pa- userContentWrapper\"><div cla...          0   \n",
       "3       <div class=\"_5pcr userContentWrapper\"><div cla...          0   \n",
       "4       <div class=\"_5pa- userContentWrapper\"><div cla...          0   \n",
       "...                                                   ...        ...   \n",
       "162319  <div class=\"_5pcr userContentWrapper\"><div cla...         12   \n",
       "162320  <div class=\"_5pcr userContentWrapper\"><div cla...          0   \n",
       "162321  <div class=\"_5pcr userContentWrapper\"><div cla...          0   \n",
       "162322  <div class=\"_5pa- userContentWrapper\"><div cla...          7   \n",
       "162323  <div class=\"_5pcr userContentWrapper\"><div cla...          0   \n",
       "\n",
       "        not_political                                        title  \\\n",
       "0                   0                League of Conservation Voters   \n",
       "1                   0                            Indivisible Guide   \n",
       "2                   0               International Rescue Committee   \n",
       "3                   0                 Covenant House International   \n",
       "4                   1                           Planned Parenthood   \n",
       "...               ...                                          ...   \n",
       "162319              0                        Keep Them Accountable   \n",
       "162320              0  National Republican Congressional Committee   \n",
       "162321              0                              POW Action Fund   \n",
       "162322              0                                Beto O'Rourke   \n",
       "162323              0                                         ACLU   \n",
       "\n",
       "                                                  message  \\\n",
       "0       <p>BREAKING: Trump’s Department of the Interio...   \n",
       "1       <p>The Mueller investigation is over. Special ...   \n",
       "2       <p>Zimbabwe is reeling from the impact of Cycl...   \n",
       "3       <p>What more can you do in the final hours of ...   \n",
       "4       <p>Say it loud, say it proud: Our rights, our ...   \n",
       "...                                                   ...   \n",
       "162319  <p>Rep. Katko voted for tax breaks for his wea...   \n",
       "162320  <p>Illinois early voting is open NOW &amp; you...   \n",
       "162321  <p>From your favorite peaks to the polling pla...   \n",
       "162322  <p>Beto just announced he’s running for presid...   \n",
       "162323  <p>Claim your FREE ACLU Voter sticker today to...   \n",
       "\n",
       "                                                thumbnail  \\\n",
       "0       https://pp-facebook-ads.s3.amazonaws.com/v/t1....   \n",
       "1       https://pp-facebook-ads.s3.amazonaws.com/v/t1....   \n",
       "2       https://pp-facebook-ads.s3.amazonaws.com/v/t1....   \n",
       "3       https://pp-facebook-ads.s3.amazonaws.com/v/t1....   \n",
       "4       https://pp-facebook-ads.s3.amazonaws.com/v/t1....   \n",
       "...                                                   ...   \n",
       "162319  https://pp-facebook-ads.s3.amazonaws.com/v/t1....   \n",
       "162320  https://pp-facebook-ads.s3.amazonaws.com/v/t1....   \n",
       "162321  https://pp-facebook-ads.s3.amazonaws.com/v/t1....   \n",
       "162322  https://pp-facebook-ads.s3.amazonaws.com/v/t1....   \n",
       "162323  https://pp-facebook-ads.s3.amazonaws.com/v/t1....   \n",
       "\n",
       "                           created_at                     updated_at   lang  \\\n",
       "0       2019-03-27 16:52:25.625455+00  2019-03-27 16:52:25.625455+00  en-US   \n",
       "1       2019-03-27 17:28:14.096849+00  2019-03-27 17:28:14.096849+00  en-US   \n",
       "2       2019-03-27 17:38:23.101377+00  2019-03-27 17:38:23.101377+00  en-US   \n",
       "3       2018-12-30 20:59:13.879124+00  2018-12-30 20:59:13.879124+00  en-US   \n",
       "4       2019-03-27 17:18:29.764002+00  2019-04-11 15:02:58.081112+00  en-US   \n",
       "...                               ...                            ...    ...   \n",
       "162319  2018-10-19 10:31:52.466563+00   2018-10-22 11:40:06.24382+00  en-US   \n",
       "162320  2018-10-24 20:41:42.111865+00  2018-10-24 20:41:42.111865+00  en-US   \n",
       "162321   2018-10-09 20:03:32.81012+00   2018-10-09 20:03:32.81012+00  en-US   \n",
       "162322  2019-03-15 03:07:40.590249+00   2019-03-22 17:01:05.36319+00  en-US   \n",
       "162323  2018-08-08 02:54:51.076959+00  2018-08-08 20:03:36.302904+00  en-US   \n",
       "\n",
       "        ... suppressed                                            targets  \\\n",
       "0       ...          f                                                 []   \n",
       "1       ...          f                                                 []   \n",
       "2       ...          f                                                 []   \n",
       "3       ...          f  [{\"target\": \"Activity on the Facebook Family\"}...   \n",
       "4       ...          f                                                 []   \n",
       "...     ...        ...                                                ...   \n",
       "162319  ...          f  [{\"target\": \"Age\", \"segment\": \"18 and older\"},...   \n",
       "162320  ...          f  [{\"target\": \"List\"}, {\"target\": \"Age\", \"segmen...   \n",
       "162321  ...          f  [{\"target\": \"Segment\", \"segment\": \"US politics...   \n",
       "162322  ...          f                                                 []   \n",
       "162323  ...          f  [{\"target\": \"Age\", \"segment\": \"35 to 54\"}, {\"t...   \n",
       "\n",
       "                                         advertiser  \\\n",
       "0                                               NaN   \n",
       "1                                               NaN   \n",
       "2                                               NaN   \n",
       "3                      Covenant House International   \n",
       "4                                               NaN   \n",
       "...                                             ...   \n",
       "162319                        Keep Them Accountable   \n",
       "162320  National Republican Congressional Committee   \n",
       "162321                              POW Action Fund   \n",
       "162322                                          NaN   \n",
       "162323                                         ACLU   \n",
       "\n",
       "                                                 entities  \\\n",
       "0       [{\"entity\": \"Endangered Species Act\", \"entity_...   \n",
       "1       [{\"entity\": \"Americans\", \"entity_type\": \"Group...   \n",
       "2       [{\"entity\": \"Zimbabwe\", \"entity_type\": \"Region\"}]   \n",
       "3                                                      []   \n",
       "4       [{\"entity\": \"Planned Parenthood\", \"entity_type...   \n",
       "...                                                   ...   \n",
       "162319     [{\"entity\": \"Katko\", \"entity_type\": \"Person\"}]   \n",
       "162320  [{\"entity\": \"Illinois\", \"entity_type\": \"Region...   \n",
       "162321                                                 []   \n",
       "162322      [{\"entity\": \"Beto\", \"entity_type\": \"Region\"}]   \n",
       "162323                                                 []   \n",
       "\n",
       "                                                     page  \\\n",
       "0                      https://www.facebook.com/LCVoters/   \n",
       "1              https://www.facebook.com/indivisibleguide/   \n",
       "2       https://www.facebook.com/InternationalRescueCo...   \n",
       "3                 https://www.facebook.com/CovenantHouse/   \n",
       "4             https://www.facebook.com/PlannedParenthood/   \n",
       "...                                                   ...   \n",
       "162319    https://www.facebook.com/KeepThemAccountable18/   \n",
       "162320                     https://www.facebook.com/NRCC/   \n",
       "162321            https://www.facebook.com/POWActionFund/   \n",
       "162322              https://www.facebook.com/betoorourke/   \n",
       "162323                     https://www.facebook.com/aclu/   \n",
       "\n",
       "                                               lower_page  \\\n",
       "0                      https://www.facebook.com/lcvoters/   \n",
       "1              https://www.facebook.com/indivisibleguide/   \n",
       "2       https://www.facebook.com/internationalrescueco...   \n",
       "3                 https://www.facebook.com/covenanthouse/   \n",
       "4             https://www.facebook.com/plannedparenthood/   \n",
       "...                                                   ...   \n",
       "162319    https://www.facebook.com/keepthemaccountable18/   \n",
       "162320                     https://www.facebook.com/nrcc/   \n",
       "162321            https://www.facebook.com/powactionfund/   \n",
       "162322              https://www.facebook.com/betoorourke/   \n",
       "162323                     https://www.facebook.com/aclu/   \n",
       "\n",
       "                                               targetings  \\\n",
       "0                                                     NaN   \n",
       "1                                                     NaN   \n",
       "2                                                     NaN   \n",
       "3       {\"<div><div class=\\\"_4-i0 _26c5\\\"><div class=\\...   \n",
       "4                                                     NaN   \n",
       "...                                                   ...   \n",
       "162319  {\"<div><div class=\\\"_4-i0 _26c5\\\"><div class=\\...   \n",
       "162320  {\"<div><div class=\\\"_4-i0 _26c5\\\"><div class=\\...   \n",
       "162321  {\"<div><div class=\\\"_4-i0 _26c5\\\"><div class=\\...   \n",
       "162322                                                NaN   \n",
       "162323  {\"<div><div class=\\\"_4-i0 _26c5\\\"><div class=\\...   \n",
       "\n",
       "                                              paid_for_by targetedness  \\\n",
       "0                           League of Conservation Voters          NaN   \n",
       "1                                     Indivisible Project          NaN   \n",
       "2                          International Rescue Committee          NaN   \n",
       "3                            Covenant House International          5.0   \n",
       "4                Planned Parenthood Federation of America          NaN   \n",
       "...                                                   ...          ...   \n",
       "162319  HOUSE MAJORITY PAC, (202) 849-6052, AND PRIORI...          7.0   \n",
       "162320  the NRCC and not authorized by any candidate o...          4.0   \n",
       "162321                    Protect Our Winters Action Fund          4.0   \n",
       "162322                                   Beto for America          NaN   \n",
       "162323                                           the ACLU          6.0   \n",
       "\n",
       "       listbuilding_fundraising_proba  \n",
       "0                            0.647945  \n",
       "1                            0.350635  \n",
       "2                            0.999909  \n",
       "3                                 NaN  \n",
       "4                            0.999977  \n",
       "...                               ...  \n",
       "162319                       0.116965  \n",
       "162320                       0.312412  \n",
       "162321                       0.205220  \n",
       "162322                       0.999994  \n",
       "162323                       0.354132  \n",
       "\n",
       "[162324 rows x 24 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fb = pd.read_csv('fbpac-ads-en-US.csv.xz') #'/Users/mehrunisaqayyum/Downloads/work/fbpac.csv'\n",
    "fb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'html', 'political', 'not_political', 'title', 'message',\n",
       "       'thumbnail', 'created_at', 'updated_at', 'lang', 'images',\n",
       "       'impressions', 'political_probability', 'targeting', 'suppressed',\n",
       "       'targets', 'advertiser', 'entities', 'page', 'lower_page', 'targetings',\n",
       "       'paid_for_by', 'targetedness', 'listbuilding_fundraising_proba'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fb.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                 object\n",
       "html                               object\n",
       "political                           int64\n",
       "not_political                       int64\n",
       "title                              object\n",
       "message                            object\n",
       "thumbnail                          object\n",
       "created_at                         object\n",
       "updated_at                         object\n",
       "lang                               object\n",
       "images                             object\n",
       "impressions                         int64\n",
       "political_probability             float64\n",
       "targeting                          object\n",
       "suppressed                         object\n",
       "targets                            object\n",
       "advertiser                         object\n",
       "entities                           object\n",
       "page                               object\n",
       "lower_page                         object\n",
       "targetings                         object\n",
       "paid_for_by                        object\n",
       "targetedness                      float64\n",
       "listbuilding_fundraising_proba    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fb.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>message</th>\n",
       "      <th>paid_for_by</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>League of Conservation Voters</td>\n",
       "      <td>&lt;p&gt;BREAKING: Trump’s Department of the Interio...</td>\n",
       "      <td>League of Conservation Voters</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Indivisible Guide</td>\n",
       "      <td>&lt;p&gt;The Mueller investigation is over. Special ...</td>\n",
       "      <td>Indivisible Project</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>International Rescue Committee</td>\n",
       "      <td>&lt;p&gt;Zimbabwe is reeling from the impact of Cycl...</td>\n",
       "      <td>International Rescue Committee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Covenant House International</td>\n",
       "      <td>&lt;p&gt;What more can you do in the final hours of ...</td>\n",
       "      <td>Covenant House International</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Planned Parenthood</td>\n",
       "      <td>&lt;p&gt;Say it loud, say it proud: Our rights, our ...</td>\n",
       "      <td>Planned Parenthood Federation of America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162309</th>\n",
       "      <td>AFT - American Federation of Teachers</td>\n",
       "      <td>&lt;p&gt;Mike DeWine was elected as Ohio’s attorney ...</td>\n",
       "      <td>AFT - American Federation of Teachers, not aut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162310</th>\n",
       "      <td>MoveOn</td>\n",
       "      <td>&lt;p&gt;We resisted and won control of the House! N...</td>\n",
       "      <td>MoveOn.org Political Action, pol.moveon.org, n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162311</th>\n",
       "      <td>AAAS - The American Association for the Advanc...</td>\n",
       "      <td>&lt;p&gt;Diversity in science, technology, and engin...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162312</th>\n",
       "      <td>Nathan Fletcher for County Supervisor 2018</td>\n",
       "      <td>&lt;p&gt;As Supervisor, I will stand up to the polit...</td>\n",
       "      <td>Nathan Fletcher for Supervisor 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162313</th>\n",
       "      <td>Industry City</td>\n",
       "      <td>&lt;p&gt;Support Industry City's plan to create 15,0...</td>\n",
       "      <td>Industry City</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>162314 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    title  \\\n",
       "0                           League of Conservation Voters   \n",
       "1                                       Indivisible Guide   \n",
       "2                          International Rescue Committee   \n",
       "3                            Covenant House International   \n",
       "4                                      Planned Parenthood   \n",
       "...                                                   ...   \n",
       "162309              AFT - American Federation of Teachers   \n",
       "162310                                             MoveOn   \n",
       "162311  AAAS - The American Association for the Advanc...   \n",
       "162312         Nathan Fletcher for County Supervisor 2018   \n",
       "162313                                      Industry City   \n",
       "\n",
       "                                                  message  \\\n",
       "0       <p>BREAKING: Trump’s Department of the Interio...   \n",
       "1       <p>The Mueller investigation is over. Special ...   \n",
       "2       <p>Zimbabwe is reeling from the impact of Cycl...   \n",
       "3       <p>What more can you do in the final hours of ...   \n",
       "4       <p>Say it loud, say it proud: Our rights, our ...   \n",
       "...                                                   ...   \n",
       "162309  <p>Mike DeWine was elected as Ohio’s attorney ...   \n",
       "162310  <p>We resisted and won control of the House! N...   \n",
       "162311  <p>Diversity in science, technology, and engin...   \n",
       "162312  <p>As Supervisor, I will stand up to the polit...   \n",
       "162313  <p>Support Industry City's plan to create 15,0...   \n",
       "\n",
       "                                              paid_for_by  \n",
       "0                           League of Conservation Voters  \n",
       "1                                     Indivisible Project  \n",
       "2                          International Rescue Committee  \n",
       "3                            Covenant House International  \n",
       "4                Planned Parenthood Federation of America  \n",
       "...                                                   ...  \n",
       "162309  AFT - American Federation of Teachers, not aut...  \n",
       "162310  MoveOn.org Political Action, pol.moveon.org, n...  \n",
       "162311                                                NaN  \n",
       "162312                Nathan Fletcher for Supervisor 2018  \n",
       "162313                                      Industry City  \n",
       "\n",
       "[162314 rows x 3 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fe = ['title','message','paid_for_by']\n",
    "text_fb = fb[fe]\n",
    "text_fb.head(-10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Cleaning\n",
    "We will review text in columns 'title','message','paid_for_by' for our Natural Language Processing project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Remove punctuation and \"weird stuff like --\" from ['title','message','paid_for_by'].'''\n",
    "\n",
    "import re\n",
    "\n",
    "def text_cleaner(text_fb):\n",
    "    # Visual inspection identifies a form of punctuation spaCy does not\n",
    "    # recognize: the double dash '--'.  Better get rid of it now!\n",
    "    text = re.sub(r'--',' ',text_fb)\n",
    "    text = re.sub(\"[\\[].*?[\\]]\", \"\", text_fb)\n",
    "    text = ' '.join(text_fb.split())\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Make text lowercase, remove text in square brackets, remove punctuation and remove words containing numbers.'''\n",
    "import re\n",
    "import string\n",
    "\n",
    "def clean_text_round1(text_fb):\n",
    "    text = text_fb.title.str.lower()\n",
    "    text = text_fb.message.str.lower()\n",
    "    text = text_fb.paid_for_by.str.lower()\n",
    "    text = re.sub('\\[.*?\\]', '', text_fb)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text_fb)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text_fb)\n",
    "    return text_fb\n",
    "\n",
    "round1 = lambda x: clean_text_round1(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                       league of conservation voters\n",
       "1                                   indivisible guide\n",
       "2                      international rescue committee\n",
       "3                        covenant house international\n",
       "4                                  planned parenthood\n",
       "                             ...                     \n",
       "162319                          keep them accountable\n",
       "162320    national republican congressional committee\n",
       "162321                                pow action fund\n",
       "162322                                  beto o'rourke\n",
       "162323                                           aclu\n",
       "Name: title, Length: 162324, dtype: object"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_fb.title.str.lower()\n",
    "#applied lower case method to title column\n",
    "#how to iterate over every row?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected string or bytes-like object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-68-7bb4c95957e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Example: alice = text_cleaner(alice)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtext_fb_nlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclean_text_round1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_fb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-67-924dadcb504e>\u001b[0m in \u001b[0;36mclean_text_round1\u001b[0;34m(text_fb)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext_fb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext_fb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpaid_for_by\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\[.*?\\]'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_fb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'[%s]'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mescape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpunctuation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_fb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\w*\\d\\w*'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_fb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/re.py\u001b[0m in \u001b[0;36msub\u001b[0;34m(pattern, repl, string, count, flags)\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[0ma\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mit\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0ms\u001b[0m \u001b[0mpassed\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0mobject\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmust\u001b[0m \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m     a replacement string to be used.\"\"\"\n\u001b[0;32m--> 191\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_compile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msubn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: expected string or bytes-like object"
     ]
    }
   ],
   "source": [
    "#Example: alice = text_cleaner(alice)\n",
    "text_fb_nlp = clean_text_round1(text_fb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Methodology Note: \n",
    "We need to parse the cleaned data. The cleaned data represents the Facebook text in the 'message' column. We could include the 'title' column as well to match the 'title' with the corresponding message as a measure of checking authenticity the way the New York Times Challenge demonstrated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'text_fb_nlp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-69-011f12a0c0f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Parse the cleaned ads. This can take a bit.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mnlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'en_core_web_lg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mfb_ad_doc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_fb_nlp\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#doc = nlp(\"string\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#Iterate over tokens in a doc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'text_fb_nlp' is not defined"
     ]
    }
   ],
   "source": [
    "# Parse the cleaned ads. This can take a bit.\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "fb_ad_doc = nlp(text_fb_nlp)  #doc = nlp(\"string\")\n",
    "\n",
    "#Iterate over tokens in a doc\n",
    "for token in fb_ad_doc:\n",
    "    print(token.text) #print (token.text)\n",
    "    \n",
    "    #Don't forget sentences_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing second Facebook dataset to argue for business case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fb_likes = pd.read_csv('/Users/mehrunisaqayyum/Downloads/pseudo_facebook.csv')\n",
    "fb_likes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concatenating\n",
    "fb_df2 = pd.concat([fb, fb_likes], ignore_index=True, sort =True)\n",
    "fb_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fb_df2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fb_df2.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Description: Second Facebook Dataset\n",
    "\n",
    "ad_id is the id of specific ad set | Numeric\n",
    "\n",
    "Reporting_start and reporting_end are the start and end dates of the each ad | Numeric\n",
    "\n",
    "Campaign_id is the id assigned by the ad running company | Numeric- Negligible\n",
    "\n",
    "fb_campaign_id is the id assigned by facebook for every ad set| Numeric- Negligible\n",
    "\n",
    "age and gender talk about the demographics | Categorical\n",
    "\n",
    "Interest1, Interest2, Interest3 are the user interests and likes of facebook users who were targeted for the ad | Categorical \n",
    "\n",
    "Impressions are the number of times the ad was shown to the users |Numeric\n",
    "\n",
    "Clicks is the number of time users clicked on the ad | Numeric\n",
    "\n",
    "spent is the amount of money spent on each campaign | Numeric\n",
    "\n",
    "Totalconversions is the number of users who have clicked the ad and have made a purchase or installed an app\n",
    "approved_conversions tells how many became actual active users | Numerica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation: We have columns like \"political\", 'not_political', 'title' and 'message' of the advertisement; 'created at'; 'lang' for languages; 'political_probabilty', and 'paid_for_by'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>political</th>\n",
       "      <th>not_political</th>\n",
       "      <th>impressions</th>\n",
       "      <th>political_probability</th>\n",
       "      <th>targetedness</th>\n",
       "      <th>listbuilding_fundraising_proba</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>162324.000000</td>\n",
       "      <td>162324.000000</td>\n",
       "      <td>162324.000000</td>\n",
       "      <td>162324.000000</td>\n",
       "      <td>112747.000000</td>\n",
       "      <td>152394.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.177663</td>\n",
       "      <td>0.794214</td>\n",
       "      <td>4.605049</td>\n",
       "      <td>0.928099</td>\n",
       "      <td>3.939723</td>\n",
       "      <td>0.545964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>10.574403</td>\n",
       "      <td>2.770883</td>\n",
       "      <td>40.689815</td>\n",
       "      <td>0.169513</td>\n",
       "      <td>1.758957</td>\n",
       "      <td>0.333821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.951812</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.265190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997825</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.423612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.999978</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.999893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>488.000000</td>\n",
       "      <td>330.000000</td>\n",
       "      <td>3575.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1.230622</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           political  not_political    impressions  political_probability  \\\n",
       "count  162324.000000  162324.000000  162324.000000          162324.000000   \n",
       "mean        4.177663       0.794214       4.605049               0.928099   \n",
       "std        10.574403       2.770883      40.689815               0.169513   \n",
       "min         0.000000       0.000000       0.000000               0.000079   \n",
       "25%         0.000000       0.000000       1.000000               0.951812   \n",
       "50%         1.000000       0.000000       1.000000               0.997825   \n",
       "75%         4.000000       1.000000       2.000000               0.999978   \n",
       "max       488.000000     330.000000    3575.000000               1.000000   \n",
       "\n",
       "        targetedness  listbuilding_fundraising_proba  \n",
       "count  112747.000000                   152394.000000  \n",
       "mean        3.939723                        0.545964  \n",
       "std         1.758957                        0.333821  \n",
       "min         0.000000                        0.000091  \n",
       "25%         3.000000                        0.265190  \n",
       "50%         4.000000                        0.423612  \n",
       "75%         4.000000                        0.999893  \n",
       "max        12.000000                        1.230622  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fb.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descriptive Statistics: Average Dollars Spent on Facebook Ads\n",
    "From another dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clicks_df = pd.read_csv('/Users/mehrunisaqayyum/Downloads/datasets_104115_247225_data.csv')\n",
    "clicks_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clicks_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Used 'clicks' and 'spent' to calculate the cost per click and per ad.\n",
    "\n",
    "click_count_per_add = clicks_df.clicks.sum()/clicks_df.clicks.count()\n",
    "click_ratio = (clicks_df.spent.sum()/63)/clicks_df.clicks.count()\n",
    "ad_spend_count_ratio = (clicks_df.spent.sum()/63)/clicks_df.clicks.count()\n",
    "print('Total number of Ads purcheased by IRA from 2015 to 2017: ', clicks_df.clicks.count())\n",
    "print('Total dollar spent by IRA from 2015 to 2017: ${:.2f}'.format(clicks_df.spent.sum()/63))\n",
    "print('Average cost per Ad: ${:.2f}'.format(ad_spend_count_ratio))\n",
    "print('Average number of clicks per Ad: {:.2f}'.format(click_count_per_add))\n",
    "print('Avg cost per click: ${:.2f}'.format(click_ratio))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observation\n",
    "We see that we have 162,314 records of political ad data on Facebook. The last ten sample how ads were purchased by nonpartisan groups, like \"League of Conservation Voters\", political organizer groups, like \"Indivisible Project\", unions \"AFT\", and international nonprofits like \"International Rescue Committee\". \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse the Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pickle Data on Facebook ads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's pickle it for later use\n",
    "data_df.to_pickle(\"corpus.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop=set(stopwords.words('english'))\n",
    "\n",
    "def build_list(fb,col=\"title\"):\n",
    "    corpus=[]\n",
    "    lem=WordNetLemmatizer()\n",
    "    stop=set(stopwords.words('english'))\n",
    "    new= fb[col].dropna().str.split()\n",
    "    new=new.values.tolist()\n",
    "    corpus=[lem.lemmatize(word.lower()) for i in new for word in i if(word) not in stop]\n",
    "    \n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semantic Analysis: Turning FB message into Vectors\n",
    "We note the stop words and review counts of words from tf-idf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turning FB message into Vectors\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "X_train, X_test = train_test_split(emma_paras, test_size=0.4, random_state=0)\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_df=0.5, # drop words that occur in more than half the paragraphs\n",
    "                             min_df=2, # only use words that appear at least twice\n",
    "                             stop_words='english', \n",
    "                             lowercase=False, #don't convert everything to lower case (since proper names are people who are targeted in disinfo campaigns)\n",
    "                             use_idf=True,#we definitely want to use inverse document frequencies in our weighting\n",
    "                             norm=u'l2', #Applies a correction factor so that longer paragraphs and shorter paragraphs get treated equally\n",
    "                             smooth_idf=True #Adds 1 to all document frequencies, as if an extra document existed that used every word once.  Prevents divide-by-zero errors\n",
    "                            )\n",
    "\n",
    "\n",
    "#Applying the vectorizer\n",
    "fb_message_tfidf =vectorizer.fit_transform(text_fb)\n",
    "print(\"Number of features: %d\" % fb_message_tfidf.get_shape()[1])\n",
    "\n",
    "#splitting into training and test sets\n",
    "X_train_tfidf, X_test_tfidf= train_test_split(fb_message_tfidf, test_size=0.4, random_state=0)\n",
    "\n",
    "\n",
    "#Reshapes the vectorizer output into something people can read\n",
    "X_train_tfidf_csr = X_train_tfidf.tocsr()\n",
    "\n",
    "#number of paragraphs\n",
    "n = X_train_tfidf_csr.shape[0]\n",
    "#A list of dictionaries, one per paragraph\n",
    "tfidf_bypara = [{} for _ in range(0,n)]\n",
    "#List of features\n",
    "terms = vectorizer.get_feature_names()\n",
    "\n",
    "print(terms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for each paragraph, lists the feature words and their tf-idf scores\n",
    "for i, j in zip(*X_train_tfidf_csr.nonzero()):\n",
    "    tfidf_bypara[i][terms[j]] = X_train_tfidf_csr[i, j]\n",
    "\n",
    "#Keep in mind that the log base 2 of 1 is 0, so a tf-idf score of 0 indicates that the word was present once in that sentence.\n",
    "print('Original sentence:', X_train[5])\n",
    "print('Tf_idf vector:', tfidf_bypara[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus=build_list(text_fb)\n",
    "counter=Counter(corpus)\n",
    "most=counter.most_common()\n",
    "x=[]\n",
    "y=[]\n",
    "for word,count in most[:20]:\n",
    "    if (word not in stop) :\n",
    "        x.append(word)\n",
    "        y.append(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,7))\n",
    "sns.barplot(x=y,y=x)\n",
    "plt.title(\"most common word in title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observations:\n",
    "Top 5 most common words are ranked:\n",
    "    1) 'Committee'\n",
    "    2)'International'\n",
    "    3) 'Action' and 'Planned'\n",
    "    4) 'Parenthood'\n",
    "    \n",
    "USA and 'America' are interchangeable--so maybe these are double-counting. \n",
    "\n",
    "'Democratic' not used as much as nonpolitical word of 'rescue'. However, we do not see 'Republican' or 'GOP'. \n",
    "\n",
    "'Beto' and'O'Rourke' are occuring at same rate. This is the only person to show up in this political ad data set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most Common 'Paid For By'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus=build_list(text_fb,\"paid_for_by\")\n",
    "counter=Counter(corpus)\n",
    "most=counter.most_common()\n",
    "x=[]\n",
    "y=[]\n",
    "for word,count in most[:10]:\n",
    "    if (word not in stop) :\n",
    "        x.append(word)\n",
    "        y.append(count)\n",
    "        \n",
    "plt.figure(figsize=(9,7))\n",
    "sns.barplot(x=y,y=x)\n",
    "plt.title(\"Most Common Word in 'paid_for_by'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure of 'Number of Top Ad Titles'\n",
    "To highlight the ads that we would should review for fake versus true classifier to strenghten business case for impact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_count(feature, title,fb, size=1, show_percents=False):\n",
    "    f, ax = plt.subplots(1,1, figsize=(4*size, 4))\n",
    "    total = float(len(fb))\n",
    "    g = sns.countplot(fb[feature],order = fb[feature].value_counts().index[0:20], palette='Set3')\n",
    "    g.set_title(\"Number of {}\".format(title))\n",
    "    if (size > 2):\n",
    "        plt.xticks(rotation=90, size=10)\n",
    "    if(show_percents):\n",
    "        for p in ax.patches:\n",
    "            height = p.get_height()\n",
    "            ax.text(p.get_x() + p.get_width()/2.,\n",
    "                   height + 3, '{:1.2f}%'.format(100*height/total),\n",
    "                   ha=\"center\")\n",
    "    ax.set_xticklabels(ax.get_xticklabels());\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_count('title','Top Ad Titles', text_fb, 3.5)\n",
    "#plt.title(\"Number of Top Ad Titles\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure: Number of Most Popular Messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note the number (counts) of message.\n",
    "plot_count('message','message countplot', text_fb, 3.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of Words\n",
    "Defining functions to identify most common words and the create features from those words in the text. We need to create a df of the \"corpus\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We need to use fb_text_df.\n",
    " ##Do we need to create features from Bag of Words and vectorize them for the Random Forest Classifier?\n",
    "def bag_of_words(text):\n",
    "    allwords = [token.lemma_\n",
    "               for token in text\n",
    "               if not token.is_punct\n",
    "               and not token.is_stop]\n",
    "    return [item[0] for item in Counter(allwords).most_common(2000)]\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bow_features(sentences, common_words):\n",
    "    fb_text_df = pd.DataFrame(columns=common_words)\n",
    "    fb_text_df['text_sentence'] = sentences[0]\n",
    "    fb_text_df['text_source'] = sentences[1]\n",
    "    fb_text_df.loc[:,common_words] = 0\n",
    "    \n",
    "    for i, sentence in enumerate(df['text_sentence']):\n",
    "        words = [token.lemma_ \n",
    "                for token in sentence\n",
    "                if (\n",
    "                    not token.is_punct\n",
    "                    and not token.is_stop\n",
    "                    and token.lemma_ in common_words\n",
    "                )]\n",
    "        for word in words:\n",
    "            fb_text_df.loc[i, word] += 1\n",
    "        if i%100 == 0:\n",
    "            print('Processing row {}'.format(i))\n",
    "    return fb_text_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data means fb_text_df\n",
    "top_words_in_ads_dict = {}\n",
    "for c in fb_text_df.columns:\n",
    "    top = fb_text_df[c].sort_values(ascending=False).head(30)\n",
    "    top_words_in_ads_dict[c]= list(zip(top.index, top.values))\n",
    "\n",
    "top_words_in_ads_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency of Words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fb['message'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fb.message.iloc[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fb' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-4652bb36850f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtemp_variable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'fb' is not defined"
     ]
    }
   ],
   "source": [
    "temp_variable = \"\".join(fb.message.iloc[1:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert sentences into numeric vectors.\n",
    "We need to transform sentences into NUMERIC vectors so that the vectors can be included in a Random Forest Classifier model, which cannot use string values.\n",
    "\n",
    "First we must create list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List \n",
    "\n",
    "message_propoganda_list = []\n",
    "for topic in [#Need to include topic_raw like physics_raw]:\n",
    "    for sentence in topic['title','paid_for_by']['docs']: #What is docs?\n",
    "        message_propoganda_list = message_propoganda_list + sentence['message']  #Used message_propaganda for abstract\n",
    "        \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use spacy to count frequency of words\n",
    "\n",
    "!python -m spacy download en_core_web_sm\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# All the processing work is done here, so it may take a while.\n",
    "FB_political_doc = nlp(temp_variable)\n",
    "#FB_popuarity_doc = nlp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaned Text before Identifying 'Stopwords'\n",
    "from collections import Counter\n",
    "\n",
    "# Utility function to calculate how frequently words appear in the data sets.\n",
    "def word_frequencies(text, include_stop=True):\n",
    "    \n",
    "    # Build a list of words.\n",
    "    # Strip out punctuation and, optionally, stop words.\n",
    "    words = []\n",
    "    for token in text:\n",
    "        if not token.is_punct and (not token.is_stop or include_stop):\n",
    "            words.append(token.text)\n",
    "            \n",
    "    # Build and return a Counter object containing word counts.\n",
    "    return Counter(words)\n",
    "    \n",
    "# The most frequent words:\n",
    "political_freq = word_frequencies(temp_variable).most_common(10)\n",
    "#like_freq = word_frequencies().most_common(10)\n",
    "print('Political:', political_freq)\n",
    "#print('Popular:', like_freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis\n",
    "Source: https://github.com/adashofdata/nlp-in-python-tutorial/blob/master/3-Sentiment-Analysis.ipynb Regarding text data, there are a few popular techniques that we'll be going through in the next few notebooks, starting with sentiment analysis. A few key points to note with sentiment analysis.\n",
    "\n",
    "TextBlob Module: Linguistic researchers have labeled the sentiment of words based on their domain expertise. Sentiment of words can vary based on where it is in a sentence. The TextBlob module allows us to take advantage of these labels. Sentiment Labels: Each word in a corpus is labeled in terms of polarity and subjectivity (there are more labels as well, but we're going to ignore them for now). A corpus' sentiment is the average of these. Polarity: How positive or negative a word is. -1 is very negative. +1 is very positive. Subjectivity: How subjective, or opinionated a word is. 0 is fact. +1 is very much an opinion. For more info on how TextBlob coded up its sentiment function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fb_df2.loc[0:5, 'message']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TextBlob('The Mueller investigation is over').sentiment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create quick lambda functions to find the polarity and subjectivity of each message\n",
    "# Terminal / Anaconda Navigator: conda install -c conda-forge textblob\n",
    "\n",
    "pol = lambda x: TextBlob(x).sentiment.polarity\n",
    "sub = lambda x: TextBlob(x).sentiment.subjectivity\n",
    "\n",
    "fb_df2['polarity'] = fb_df2['message'].apply(pol)\n",
    "fb_df2['subjectivity'] = fb_df2['title'].apply(sub)\n",
    "fb_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loop each 'message' value\n",
    "\n",
    "for token in text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
